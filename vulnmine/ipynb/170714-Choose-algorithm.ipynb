{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the best classification algorithm\n",
    "\n",
    "### Use a k-fold cross-validation to choose the best classification algorithm\n",
    "\n",
    "From the scikit-learn documentation concerning [k-fold cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html):\n",
    "\n",
    ">To avoid it [\"overfitting\"], it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test.\n",
    "\n",
    ">In the basic approach, called *k-fold CV*, the training set is split into k smaller sets... The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "> * A model is trained using k-1 of the folds as training data;\n",
    "* the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "The following code uses this technique to evaluate the relative performance of various ML classification algorithms on the training data.\n",
    "\n",
    "RandomForest is one of the best choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zict 0.1.2\n",
      "xmltodict 0.11.0\n",
      "xlrd 1.0.0\n",
      "widgetsnbextension 2.0.0\n",
      "wheel 0.29.0\n",
      "webencodings 0.5\n",
      "wcwidth 0.1.7\n",
      "vincent 0.4.4\n",
      "urllib3 1.21.1\n",
      "traitlets 4.3.2\n",
      "tornado 4.5.1\n",
      "toolz 0.8.2\n",
      "testpath 0.3\n",
      "terminado 0.6\n",
      "tblib 1.3.2\n",
      "sympy 1.0\n",
      "subprocess32 3.2.7\n",
      "statsmodels 0.8.0\n",
      "SQLAlchemy 1.1.11\n",
      "sortedcontainers 1.5.3\n",
      "six 1.10.0\n",
      "singledispatch 3.4.0.3\n",
      "simplegeneric 0.8.1\n",
      "setuptools 36.2.0\n",
      "seaborn 0.7.1\n",
      "scipy 0.19.1\n",
      "scikit-learn 0.18.2\n",
      "scikit-image 0.12.3\n",
      "schedule 0.4.3\n",
      "scandir 1.5\n",
      "responses 0.5.1\n",
      "requests 2.18.1\n",
      "pyzmq 16.0.2\n",
      "PyYAML 3.12\n",
      "pytz 2017.2\n",
      "python-Levenshtein 0.12.0\n",
      "python-dateutil 2.6.0\n",
      "pytest 3.1.3\n",
      "PySocks 1.6.7\n",
      "pyparsing 2.2.0\n",
      "pyOpenSSL 16.2.0\n",
      "Pygments 2.2.0\n",
      "pycparser 2.18\n",
      "py 1.4.34\n",
      "ptyprocess 0.5.2\n",
      "psutil 5.2.1\n",
      "prompt-toolkit 1.0.14\n",
      "pip 9.0.1\n",
      "Pillow 4.2.1\n",
      "pickleshare 0.7.3\n",
      "pexpect 4.2.1\n",
      "pbr 3.1.1\n",
      "patsy 0.4.1\n",
      "pathlib2 2.3.0\n",
      "partd 0.3.8\n",
      "pandocfilters 1.4.1\n",
      "pandas 0.19.2\n",
      "olefile 0.44\n",
      "numpy 1.12.1\n",
      "numexpr 2.6.2\n",
      "numba 0.31.0+0.g3bb1d98.dirty\n",
      "notebook 5.0.0\n",
      "networkx 1.11\n",
      "nbformat 4.3.0\n",
      "nbconvert 5.2.1\n",
      "msgpack-python 0.4.8\n",
      "mpmath 0.19\n",
      "mock 2.0.0\n",
      "mistune 0.7.4\n",
      "matplotlib 2.0.2\n",
      "MarkupSafe 1.0\n",
      "locket 0.2.0\n",
      "llvmlite 0.16.0\n",
      "jupyter-core 4.3.0\n",
      "jupyter-client 5.1.0\n",
      "jsonschema 2.5.1\n",
      "Jinja2 2.9.5\n",
      "ipywidgets 6.0.0\n",
      "ipython 5.3.0\n",
      "ipython-genutils 0.2.0\n",
      "ipykernel 4.6.1\n",
      "ipaddress 1.0.18\n",
      "idna 2.5\n",
      "html5lib 0.9999999\n",
      "heapdict 1.0.0\n",
      "h5py 2.6.0\n",
      "fuzzywuzzy 0.15.0\n",
      "futures 3.0.5\n",
      "functools32 3.2.3.post2\n",
      "funcsigs 1.0.2\n",
      "fastcache 1.0.2\n",
      "enum34 1.1.6\n",
      "entrypoints 0.2.3\n",
      "distributed 1.18.0\n",
      "dill 0.2.6\n",
      "decorator 4.0.11\n",
      "dask 0.15.1\n",
      "Cython 0.25.2\n",
      "cryptography 1.9\n",
      "cookies 2.2.1\n",
      "configparser 3.5.0\n",
      "cloudpickle 0.2.2\n",
      "click 6.7\n",
      "chardet 3.0.4\n",
      "cffi 1.10.0\n",
      "certifi 2017.4.17\n",
      "bokeh 0.12.6\n",
      "bleach 1.5.0\n",
      "bkcharts 0.2\n",
      "beautifulsoup4 4.5.3\n",
      "backports.ssl-match-hostname 3.5.0.1\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports-abc 0.5\n",
      "asn1crypto 0.22.0\n",
      "cycler 0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pip #needed to use the pip functions\n",
    "\n",
    "# Show versions of all installed software to help debug incompatibilities.\n",
    "\n",
    "for i in pip.get_installed_distributions(local_only=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the vendor training data\n",
    "\n",
    "Read in the manually labelled vendor training data.\n",
    "\n",
    "Format it and convert to two numpy arrays for input to the scikit-learn ML algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10110, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df_label_vendors = pd.io.parsers.read_csv(\n",
    "                            \"/home/jovyan/work/shared/data/csv/label_vendors.csv\",\n",
    "                            error_bad_lines=False,\n",
    "                            warn_bad_lines=True,\n",
    "                            quotechar='\"',\n",
    "                            encoding='utf-8')\n",
    "except IOError as e:\n",
    "    print('\\n\\n***I/O error({0}): {1}\\n\\n'.format(\n",
    "                e.errno, e.strerror))\n",
    "\n",
    "# except ValueError:\n",
    "#    self.logger.critical('Could not convert data to an integer.')\n",
    "except:\n",
    "    print(\n",
    "        '\\n\\n***Unexpected error: {0}\\n\\n'.format(\n",
    "            sys.exc_info()[0]))\n",
    "    raise\n",
    "\n",
    "# Number of records / columns\n",
    "\n",
    "df_label_vendors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10110, 7), (10110,))\n"
     ]
    }
   ],
   "source": [
    "# Format training data as \"X\" == \"features, \"y\" == target.\n",
    "# The target value is the 1st column.\n",
    "df_match_train1 = df_label_vendors[['match','fz_ptl_ratio', 'fz_ptl_tok_sort_ratio', 'fz_ratio', 'fz_tok_set_ratio', 'fz_uwratio','ven_len', 'pu0_len']]\n",
    "\n",
    "# Convert into 2 numpy arrays for the scikit-learn ML classification algorithms.\n",
    "np_match_train1 = np.asarray(df_match_train1)\n",
    "X, y = np_match_train1[:, 1:], np_match_train1[:, 0]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier, Accuracy: 0.97 (+/- 0.02)\n",
      "Ridge Classifier #2, Accuracy: 0.97 (+/- 0.02)\n",
      "Perceptron, Accuracy: 0.93 (+/- 0.05)\n",
      "Passive-Aggressive, Accuracy: 0.93 (+/- 0.03)\n",
      "kNN, Accuracy: 0.98 (+/- 0.01)\n",
      "Nearest Centroid, Accuracy: 0.90 (+/- 0.04)\n",
      "Random forest, Accuracy: 0.98 (+/- 0.01)\n",
      "SGD / SVM, Accuracy: 0.89 (+/- 0.21)\n",
      "Naive Bayes, Accuracy: 0.78 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "# set up for k-fold cross-validation to choose best model\n",
    "\n",
    "#rom sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "for clf, clf_name in (\n",
    "\t\t(RidgeClassifier(alpha=1.0), \"Ridge Classifier\"),\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier #2\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (NearestCentroid(), \"Nearest Centroid\"),\n",
    "        (RandomForestClassifier(n_estimators=100, class_weight=\"auto\"), \"Random forest\"),\n",
    "\t\t(SGDClassifier(alpha=.0001, n_iter=50, penalty=\"l2\"), \"SGD / SVM\"),\n",
    "\t\t(MultinomialNB(alpha=.01), \"Naive Bayes\")):\n",
    "\n",
    "\tscores = cross_val_score(clf, X, y, cv=5)\n",
    "\tprint(\"%s, Accuracy: %0.2f (+/- %0.2f)\" % (clf_name, scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
